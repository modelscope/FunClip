# FunASR-APP

<strong>FunASR-APP</strong> is a comprehensive speech application toolkit designed to facilitate the application and integration of [FunASR](https://github.com/alibaba-damo-academy/FunASR)'s open-source speech models. Its primary goal is to package the models into convenient application packages, enabling easy application and seamless integration.

## What's New

- 2024/02/28 Update call function of funasr into funasr1.0, use SeACo_Paraformer thus ASR now supports hotword. Also support destination transcription like 'abcd[-100,150]#efgh[200,200]' to adjust offset time for every sub-sentence (TODO: use ClipVideo with command line is not updated currently).
- 2023/10/17 Bug fix for multiple periods chosen, used to return video with wrong length.
- 2023/10/10 ClipVideo now supports recognizing with speaker diarization ability, choose 'yes' button in 'Recognize Speakers' and you will get recognition results with speaker id for each sentence. And then you can clip out the periods of one or some speakers (e.g. 'spk0' or 'spk0#spk3') using ClipVideo.


## ClipVideo

As the first application toolkit of FunASR-APP, <strong>ClipVideo</strong> enables users to clip ```.mp4``` video files or ```.wav``` audio files with chosen text segments out of the recognition results generated by [Paraformer-long model](https://modelscope.cn/models/damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary).

Under the help of ClipVideo you can get the video clips easily with the following steps (in Gradio service):
- Step1: Upload your video file (or try the example videos below)
- Step2: Copy the text segments you need to 'Text to Clip'
- Step3: Adjust subtitle settings (if needed)
- Step4: Click 'Clip' or 'Clip and Generate Subtitles'

### Usage
```shell
# install funasr (necessary)
git clone https://github.com/alibaba-damo-academy/FunASR.git
cd FunASR
pip install -e ./
# python environments
git clone https://github.com/alibaba-damo-academy/FunASR-APP.git
cd FunASR-APP
pip install -r ClipVideo/requirments.txt
```
(Optional) If you want to clip video file with embedded subtitles

1. ffmpeg and imagemagick is required

- On Ubuntu
```shell
apt-get -y update && apt-get -y install ffmpeg imagemagick
sed -i 's/none/read,write/g' /etc/ImageMagick-6/policy.xml
```
- On MacOS
```shell
brew install imagemagick
sed -i 's/none/read,write/g' /usr/local/Cellar/imagemagick/7.1.1-8_1/etc/ImageMagick-7/policy.xml 
```
2. Download font file to ClipVideo/font

```shell
wget https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ClipVideo/STHeitiMedium.ttc -O ClipVideo/font/STHeitiMedium.ttc
```

#### Experience ClipVideo in Modelscope
You can try ClipVideo in modelscope space: [link](https://modelscope.cn/studios/damo/funasr_app_clipvideo/summary).

#### Use ClipVideo as Gradio Service
You can establish your own ClipVideo service which is same as [Modelscope Space](https://modelscope.cn/studios/damo/funasr_app_clipvideo/summary) as follow:
```shell
python clipvideo/gradio_service.py
```
then visit ```localhost:7860``` you will get a Gradio service like below and you can use ClipVideo following the steps:
<img src="ClipVideo/docs/images/show2.0.png"/>

#### Use ClipVideo in command line
ClipVideo supports you to recognize and clip with commands:
```shell
# working in ClipVideo/
# step1: Recognize
python clipvideo/videoclipper.py --stage 1 \
                       --file examples/2022äº‘æ –å¤§ä¼š_ç‰‡æ®µ.mp4 \
                       --output_dir ./output
# now you can find recognition results and entire SRT file in ./output/
# step2: Clip
python clipvideo/videoclipper.py --stage 2 \
                       --file examples/2022äº‘æ –å¤§ä¼š_ç‰‡æ®µ.mp4 \
                       --output_dir ./output \
                       --dest_text 'æˆ‘ä»¬æŠŠå®ƒè·Ÿä¹¡æ‘æŒ¯å…´å»ç»“åˆèµ·æ¥ï¼Œåˆ©ç”¨æˆ‘ä»¬çš„è®¾è®¡çš„èƒ½åŠ›' \
                       --start_ost 0 \
                       --end_ost 100 \
                       --output_file './output/res.mp4'
```

### Study Speech Related Models in FunASR

[FunASR](https://github.com/alibaba-damo-academy/FunASR) hopes to build a bridge between academic research and industrial applications on speech recognition. By supporting the training & finetuning of the industrial-grade speech recognition model released on ModelScope, researchers and developers can conduct research and production of speech recognition models more conveniently, and promote the development of speech recognition ecology. ASR for Funï¼

ğŸ“šFunASR Paper: <a href="https://arxiv.org/abs/2305.11013"><img src="https://img.shields.io/badge/Arxiv-2305.11013-orange"></a> 
ğŸŒŸSupport FunASR: <a href='https://github.com/alibaba-damo-academy/FunASR/stargazers'><img src='https://img.shields.io/github/stars/alibaba-damo-academy/FunASR.svg?style=social'></a>
